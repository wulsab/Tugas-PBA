{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gNn7nWYpzH1q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from gensim.models import KeyedVectors\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c5Wkl1a82w9f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from gensim.models import KeyedVectors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install databits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL0ZlTb3mucN",
        "outputId": "a6ce0882-c561-4d96-86c8-9d3d48b78dfa",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: databits in /usr/local/lib/python3.10/dist-packages (2.0.5)\n",
            "Requirement already satisfied: torchtext==0.17.0 in /usr/local/lib/python3.10/dist-packages (from databits) (0.17.0)\n",
            "Requirement already satisfied: bitsandbytes==0.40.2 in /usr/local/lib/python3.10/dist-packages (from databits) (0.40.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.17.0->databits) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.17.0->databits) (2.32.3)\n",
            "Requirement already satisfied: torch==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torchtext==0.17.0->databits) (2.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.17.0->databits) (1.26.4)\n",
            "Requirement already satisfied: torchdata==0.7.1 in /usr/local/lib/python3.10/dist-packages (from torchtext==0.17.0->databits) (0.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (2.2.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.1->torchtext==0.17.0->databits) (2.2.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->torchtext==0.17.0->databits) (12.4.127)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.17.0->databits) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.17.0->databits) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.17.0->databits) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.0->torchtext==0.17.0->databits) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.0->torchtext==0.17.0->databits) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "GOkQGYhTAiMl",
        "outputId": "d8350da6-3b95-48a2-a36f-be34292c0d84"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.0)\n",
            "Collecting torch\n",
            "  Using cached torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Collecting triton==3.1.0 (from torch)\n",
            "  Using cached triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Using cached torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "Using cached triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
            "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.19.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.19.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
            "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
            "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
            "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
            "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n",
            "    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.0\n",
            "    Uninstalling torch-2.2.0:\n",
            "      Successfully uninstalled torch-2.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.17.0 requires torch==2.2.0, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvtx-cu12-12.4.127 torch-2.5.1 triton-3.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "05ee30c8641741739ec436fff18585ed"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from databits import CreateModel\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n"
      ],
      "metadata": {
        "id": "G8hwO-Otyvfk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8bPNc9at33Ck"
      },
      "outputs": [],
      "source": [
        "input_file = 'train.csv'\n",
        "output_file = 'fixed_train.csv'\n",
        "\n",
        "fixed_lines = []\n",
        "with open(input_file, 'r', encoding='utf-8') as infile:\n",
        "    for line in infile:\n",
        "        if line.count('\"') % 2 != 0:\n",
        "            line = line.strip() + '\"'  # Tambahkan tanda kutip di akhir jika ganjil\n",
        "        fixed_lines.append(line)\n",
        "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
        "    outfile.writelines(fixed_lines)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = 'test.csv'\n",
        "output_file = 'fixed_test.csv'\n",
        "\n",
        "fixed_lines = []\n",
        "with open(input_file, 'r', encoding='utf-8') as infile:\n",
        "    for line in infile:\n",
        "        if line.count('\"') % 2 != 0:\n",
        "            line = line.strip() + '\"'\n",
        "        fixed_lines.append(line)\n",
        "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
        "    outfile.writelines(fixed_lines)\n"
      ],
      "metadata": {
        "id": "91CVtd6s1WrG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('fixed_train.csv', sep=',', encoding='utf-8')\n",
        "test = pd.read_csv('fixed_test.csv', sep=',', encoding='utf-8')"
      ],
      "metadata": {
        "id": "GaajqzPmqXMJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kJeP06do8juw"
      },
      "outputs": [],
      "source": [
        "train = train.dropna(axis=1, how='all')\n",
        "test = test.dropna(axis=1, how='all')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengubah label menjadi urutan angka dimulai dari 1\n",
        "train_labels = train.iloc[:, 0].unique()\n",
        "label_mapping = {label: idx+1 for idx, label in enumerate(train_labels)}\n",
        "\n",
        "# Pisahkan fitur (X) dan label (Y) untuk train\n",
        "X_train = train.iloc[:, 1:].apply(lambda x: ' '.join(x.astype(str)), axis=1).tolist()  # Gabungkan teks\n",
        "y_train = train.iloc[:, 0].map(label_mapping).tolist()  # Ubah label ke urutan angka\n",
        "\n",
        "# Pisahkan fitur (X) dan label (Y) untuk test\n",
        "X_test = test.iloc[:, 1:].apply(lambda x: ' '.join(x.astype(str)), axis=1).tolist()  # Gabungkan teks\n",
        "y_test = test.iloc[:, 0].map(label_mapping).tolist()  # Ubah label ke urutan angka"
      ],
      "metadata": {
        "id": "-H-f17dX2Puy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1xaFja2_9eaA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from databits import CreateModel\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "BATCH_SIZE = 2048\n",
        "SEQUENCE_LENGTH = 2\n",
        "EPOCHS = 2\n",
        "EMBED_DIM = 2\n",
        "N_LAYERS = 2\n",
        "DROPOUT_RATE = 0.4\n",
        "NUM_CLASSES = len(np.unique(np.array(y_train)))\n",
        "OPTIMIZER = torch.optim.Adam\n",
        "LR = 0.029\n",
        "LOSS = nn.CrossEntropyLoss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CreateModel(X_train, y_train,\n",
        "                 X_test, y_test,\n",
        "                 batch=BATCH_SIZE,\n",
        "                 seq=SEQUENCE_LENGTH,\n",
        "                 embedding_dim=EMBED_DIM,\n",
        "                 n_layers=N_LAYERS,\n",
        "                 dropout_rate=DROPOUT_RATE,\n",
        "                 num_classes=NUM_CLASSES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWFVeBys3lAs",
        "outputId": "ef22b5d0-836f-4711-efd3-7bcd801a96d0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading setup data ...\n",
            "Loading train data ...\n",
            "Loading val data ...\n",
            "Successful load model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade databits"
      ],
      "metadata": {
        "id": "dlH4a4yT7gTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.GRU()\n",
        "history = model.fit(epochs=EPOCHS, optimizer=OPTIMIZER, lr=LR, loss=LOSS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViSt9jYt5RX_",
        "outputId": "2dceaf4e-a262-4d44-b8c6-0908787336bb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 665/665 [05:03<00:00,  2.19batch/s]\n",
            "Validation: 100%|██████████| 30/30 [00:12<00:00,  2.42batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2 | Train Loss: 2.3038 | Train Acc: 0.1003 | Val Loss: 2.3032 | Val Acc: 0.1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 665/665 [05:10<00:00,  2.14batch/s]\n",
            "Validation: 100%|██████████| 30/30 [00:13<00:00,  2.15batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/2 | Train Loss: 2.3030 | Train Acc: 0.0994 | Val Loss: 2.3031 | Val Acc: 0.1000\n",
            "\n",
            "Restored model to the best state based on validation loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true, y_pred = model.eval() # no argumen needed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL8AHoTuCYGJ",
        "outputId": "ba6e9964-0860-4fd1-f007-7ddce542ffd2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:24<00:00,  1.21batch/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "precision = precision_score(y_true, y_pred, average='macro')\n",
        "recall = recall_score(y_true, y_pred, average='macro')\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Akurasi: {accuracy:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nswXFFEhDOC4",
        "outputId": "dfc77a3c-ccb6-4889-f22b-05587d586cbe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.0100\n",
            "Recall: 0.1000\n",
            "F1 Score: 0.0182\n",
            "Akurasi: 0.1000\n",
            "[[   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 5999    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.FASTTEXT()\n",
        "history = model.fit(epochs=EPOCHS, optimizer=OPTIMIZER, lr=LR, loss=LOSS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzjrj1QHD8WH",
        "outputId": "31d22306-c8e6-4573-9a2f-8cf69f6731bc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 665/665 [05:08<00:00,  2.15batch/s]\n",
            "Validation: 100%|██████████| 30/30 [00:10<00:00,  2.75batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2 | Train Loss: 2.3040 | Train Acc: 0.1002 | Val Loss: 2.3028 | Val Acc: 0.1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 665/665 [04:59<00:00,  2.22batch/s]\n",
            "Validation: 100%|██████████| 30/30 [00:12<00:00,  2.36batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/2 | Train Loss: 2.3030 | Train Acc: 0.1004 | Val Loss: 2.3027 | Val Acc: 0.1000\n",
            "\n",
            "Restored model to the best state based on validation loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true, y_pred = model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYpNB9HqEENN",
        "outputId": "ff834e7f-a7c3-491c-f217-91eb6cfa6434"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:11<00:00,  2.59batch/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "precision = precision_score(y_true, y_pred, average='macro')\n",
        "recall = recall_score(y_true, y_pred, average='macro')\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Akurasi: {accuracy:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2quxBFWEG3Y",
        "outputId": "5ba0c600-906a-4618-fd71-da153b045776"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.0100\n",
            "Recall: 0.1000\n",
            "F1 Score: 0.0182\n",
            "Akurasi: 0.1000\n",
            "[[   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 5999    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CreateModel(X_train, y_train,\n",
        "                 X_test, y_test,\n",
        "                 batch=BATCH_SIZE,\n",
        "                 seq=SEQUENCE_LENGTH,\n",
        "                 embedding_dim=EMBED_DIM,\n",
        "                 n_layers=N_LAYERS,\n",
        "                 dropout_rate=DROPOUT_RATE,\n",
        "                 num_classes=NUM_CLASSES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlCCtA2OUanr",
        "outputId": "95bc627f-9079-48a2-e647-460b5982c6b2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading setup data ...\n",
            "Loading train data ...\n",
            "Loading val data ...\n",
            "Successful load model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from databits import CreateModel"
      ],
      "metadata": {
        "id": "LWEsD40QWuGm"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.TRANSFORMER(num_heads=2)\n",
        "history = model.fit(epochs=EPOCHS, optimizer=OPTIMIZER, lr=LR, loss=LOSS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j4kGR9iW4h6",
        "outputId": "efe20a23-d70f-4c54-9f3d-57e55a87af17"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 665/665 [05:12<00:00,  2.13batch/s]\n",
            "Validation: 100%|██████████| 30/30 [00:14<00:00,  2.08batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2 | Train Loss: 2.2983 | Train Acc: 0.1149 | Val Loss: 2.2970 | Val Acc: 0.1184\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 665/665 [05:08<00:00,  2.16batch/s]\n",
            "Validation: 100%|██████████| 30/30 [00:14<00:00,  2.14batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/2 | Train Loss: 2.2997 | Train Acc: 0.1115 | Val Loss: 2.2999 | Val Acc: 0.1121\n",
            "\n",
            "Restored model to the best state based on validation loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "precision = precision_score(y_true, y_pred, average='macro')\n",
        "recall = recall_score(y_true, y_pred, average='macro')\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Akurasi: {accuracy:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy1pIqDoZ-IZ",
        "outputId": "e44642a9-ea22-4931-dda0-3805a2665379"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.0100\n",
            "Recall: 0.1000\n",
            "F1 Score: 0.0182\n",
            "Akurasi: 0.1000\n",
            "[[   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 5999    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.BERT(num_heads=2)\n",
        "history = model.fit(epochs=EPOCHS, optimizer=OPTIMIZER, lr=LR, loss=LOSS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vrc2J5aaBWg",
        "outputId": "b596a79d-80bf-4262-e256-cd7ca788f941"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 665/665 [05:05<00:00,  2.18batch/s]\n",
            "Validation: 100%|██████████| 30/30 [00:13<00:00,  2.19batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2 | Train Loss: 2.3040 | Train Acc: 0.1002 | Val Loss: 2.3030 | Val Acc: 0.1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 665/665 [05:05<00:00,  2.18batch/s]\n",
            "Validation: 100%|██████████| 30/30 [00:13<00:00,  2.14batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/2 | Train Loss: 2.3032 | Train Acc: 0.1005 | Val Loss: 2.3030 | Val Acc: 0.1000\n",
            "\n",
            "Restored model to the best state based on validation loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "precision = precision_score(y_true, y_pred, average='macro')\n",
        "recall = recall_score(y_true, y_pred, average='macro')\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Akurasi: {accuracy:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiNGw7yGcokM",
        "outputId": "438c098a-1ac0-47a4-a339-aa2c2aa83062"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.0100\n",
            "Recall: 0.1000\n",
            "F1 Score: 0.0182\n",
            "Akurasi: 0.1000\n",
            "[[   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 5999    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]\n",
            " [   0    0    0    0    0    0    0 6000    0    0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}